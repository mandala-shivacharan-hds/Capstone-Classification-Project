# -*- coding: utf-8 -*-
"""ml

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1y4U7UQJVjMi2nVH_jxkoM-nSeRQoL6Ul
"""

#  Import Libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

#  Load Data
df = pd.read_csv('/content/Engineering_graduate_salary.csv')

df.info()

"""# DATA PREPROCESSING

# New section
"""

df.shape

df['DOB'] = pd.to_datetime(df['DOB'], errors='coerce')
df['Age'] = 2025 - df['DOB'].dt.year
df.drop('DOB', axis=1, inplace=True)

df.drop(['CollegeID'], axis=1, inplace=True)

df.drop(['10board'],axis=1,inplace=True)

df.drop(['ID'],axis=1,inplace=True)

df.drop(['12board'],axis=1,inplace=True)

df.info()

from sklearn.preprocessing import OneHotEncoder
import pandas as pd

# Get all object columns
object_cols = df.select_dtypes(include='object').columns.tolist()

# (Optional) If you want to exclude 'Salary' or any target column:
# object_cols.remove('Salary')

# Apply OneHotEncoder to each object column
# Use handle_unknown='ignore' to handle potential new categories in test data
encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)

# Fit and transform the selected columns
encoded_data = encoder.fit_transform(df[object_cols])

# Create a DataFrame from the encoded data with appropriate column names
encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out(object_cols))

# Drop the original object columns
df = df.drop(object_cols, axis=1)

# Concatenate the original DataFrame with the new one-hot encoded DataFrame
df = pd.concat([df, encoded_df], axis=1)

df.info()

df.isnull().sum()

df.describe()

df.shape

df.info()

# Rename columns with typos
df.rename(columns={'nueroticism': 'neuroticism','openess_to_experience':'openess'}, inplace=True)

df.info()

#Step 9: Check for duplicates
print("Duplicates:", df.duplicated().sum())
df.drop_duplicates(inplace=True)

df.shape

df.describe()

# Replace -1 with NaN in subject columns
subject_cols = [
    'ComputerProgramming', 'ElectronicsAndSemicon', 'ComputerScience',
    'MechanicalEngg', 'ElectricalEngg', 'TelecomEngg', 'CivilEngg'
]
df[subject_cols] = df[subject_cols].replace(-1, np.nan)

# List of subject columns again (in case not reused)
subject_cols = [
    'ComputerProgramming', 'ElectronicsAndSemicon', 'ComputerScience',
    'MechanicalEngg', 'ElectricalEngg', 'TelecomEngg', 'CivilEngg'
]

# Fill NaN values with column-wise mean
df[subject_cols] = df[subject_cols].fillna(df[subject_cols].mean())

print("Remaining NaNs:", df[subject_cols].isna().sum())

df.shape

df.describe()

df.shape

df.describe()

#Unique Values Per Column
for col in df.columns:
    print(f"{col}: {df[col].nunique()} unique values")

df.shape

print(df.columns.tolist())

# Function to count outliers using IQR
def count_outliers_iqr(df, columns):
    outlier_counts = {}
    for col in columns:
        Q1 = df[col].quantile(0.25)
        Q3 = df[col].quantile(0.75)
        IQR = Q3 - Q1
        lower = Q1 - 1.5 * IQR
        upper = Q3 + 1.5 * IQR
        outliers = ((df[col] < lower) | (df[col] > upper)).sum()
        outlier_counts[col] = outliers
    return outlier_counts

# Get numeric columns (except ID columns)
numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()
exclude_cols = ['ID', 'CollegeID', 'CollegeCityID']
numeric_cols = [col for col in numeric_cols if col not in exclude_cols]

# Get outlier counts
outlier_counts = count_outliers_iqr(df, numeric_cols)

# Sort and display the top outlier-heavy columns
sorted_outliers = sorted(outlier_counts.items(), key=lambda x: x[1], reverse=True)

# Print results
print("Columns with Most Outliers:\n")
for col, count in sorted_outliers:
    print(f"{col}: {count} outliers")

df.shape

from scipy.stats import zscore
import numpy as np

# Columns to apply Z-score on (make sure these exist in df)
zscore_cols = [
    'Salary', 'collegeGPA', 'Quant', 'Logical', 'English',
    'openness', 'agreeableness', 'extraversion', 'conscientiousness',
    'neuroticism', '10percentage', '12percentage', 'TestScore', 'Experience'
]

# Optional: Add 'ComputerProgramming' only if it's numeric (not binary)
if df['ComputerProgramming'].nunique() > 2:
    zscore_cols.append('ComputerProgramming')

# Filter only the existing columns
zscore_cols = [col for col in zscore_cols if col in df.columns]

# Apply Z-score
z_scores = np.abs(zscore(df[zscore_cols]))

# Threshold
threshold = 3

# Keep rows with all z-scores < threshold
df_clean = df[(z_scores < threshold).all(axis=1)]

print("Before:", df.shape)
print("After Z-score outlier removal:", df_clean.shape)

df_clean.shape

df.describe()

"""# EDA"""

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(20, 15))  # Increased figure size
sns.heatmap(df.corr(), annot=True, fmt=".2f", cmap='coolwarm', linewidths=0.5, annot_kws={"size": 8}) # Adjusted annot size
plt.title("Correlation Heatmap", fontsize=16)
plt.xticks(rotation=45, ha='right', fontsize=10) # Adjusted xticks fontsize
plt.yticks(rotation=0, fontsize=10) # Adjusted yticks fontsize
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns

# 1. Boxplot: Salary vs CollegeTier
plt.figure(figsize=(10, 5))
sns.boxplot(x='CollegeTier', y='Salary', data=df)
plt.title('Salary Distribution by College Tier')
plt.show()


# 3. Scatterplot: GPA vs Salary
plt.figure(figsize=(8, 5))
sns.scatterplot(x='collegeGPA', y='Salary', data=df)
plt.title('College GPA vs Salary')
plt.show()

# 4. Scatterplot: Quant vs Salary
plt.figure(figsize=(8, 5))
sns.scatterplot(x='Quant', y='Salary', data=df)
plt.title('Quant Score vs Salary')
plt.show()

# 5. Pairplot: Key numeric features
sns.pairplot(df[['Salary', 'collegeGPA', 'Quant', 'Logical', 'English']])
plt.show()

# 6. Violin Plot: Salary vs Domain
plt.figure(figsize=(12, 6))
sns.violinplot(x='Domain', y='Salary', data=df)
plt.title('Salary Distribution by Domain')
plt.show()

# 7. Correlation Heatmap
top_corr = df.corr()['Salary'].abs().sort_values(ascending=False).head(11).index
plt.figure(figsize=(10, 8))
sns.heatmap(df[top_corr].corr(), annot=True, cmap='coolwarm', linewidths=0.5)
plt.title("Top Correlated Features with Salary")
plt.show()

plt.figure(figsize=(8, 4))
sns.histplot(df['Salary'], kde=True, bins=30, color='teal')
plt.title('Salary Distribution')
plt.xlabel('Salary')
plt.ylabel('Frequency')
plt.show()

sns.countplot(x='CollegeTier', data=df)
plt.title('Count of Students by College Tier')
plt.show()

# Find the one-hot encoded specialization columns
specialization_cols = [col for col in df.columns if col.startswith('Specialization_')]

# Calculate the mean salary for each specialization
specialization_salaries = {}
for col in specialization_cols:
    # Filter the DataFrame to include only rows where the specialization is present (value is 1.0)
    temp_df = df[df[col] == 1.0]
    if not temp_df.empty:
        specialization_salaries[col] = temp_df['Salary'].mean()

# Convert the dictionary to a pandas Series and sort by mean salary
specialization_salaries_series = pd.Series(specialization_salaries)
top_specializations = specialization_salaries_series.sort_values(ascending=False).head(10)

# Plot the average salary for the top specializations
plt.figure(figsize=(12, 6))
sns.barplot(x=top_specializations.index, y=top_specializations.values, palette='viridis')
plt.xticks(rotation=90)
plt.xlabel('Specialization')
plt.ylabel('Average Salary')
plt.title('Top 10 Specializations by Average Salary')
plt.tight_layout()
plt.show()

df.describe()

sns.histplot(df['Salary'], kde=True)
plt.show()

"""MODELS

"""

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, f1_score, confusion_matrix

# For demonstration, let's create a binary target variable based on Salary
df['High_Salary'] = (df['Salary'] > df['Salary'].median()).astype(int)

X = df.drop(['Salary', 'High_Salary'], axis=1)
y = df['High_Salary']  # Target variable

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)

# Initialize and train a simple classification model
model = LogisticRegression(max_iter=5000) # Increased max_iter for convergence
model.fit(X_train, y_train)
# Make predictions on the test set
y_pred = model.predict(X_test)

# Calculate accuracy and F1 score
accuracy = accuracy_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print(f"Accuracy: {accuracy:.2f}")
print(f"F1 Score: {f1:.2f}")
print("\nConfusion Matrix:")
print(confusion_matrix(y_test, y_pred))

from sklearn.model_selection import cross_val_score
from sklearn.neighbors import KNeighborsClassifier

# Define features (X) and target (y)
X = df.drop(['Salary', 'High_Salary'], axis=1)  # Features
y = df['High_Salary']  # Target variable

# Initialize KNN classifier (you can still tune n_neighbors)
knn_model = KNeighborsClassifier(n_neighbors=5)

# Perform 5-fold cross-validation
cv_scores = cross_val_score(knn_model, X_train, y_train, cv=5, scoring='accuracy')

print("Cross-validation Accuracy Scores:", cv_scores)
print("Mean Cross-validation Accuracy:", cv_scores.mean())

from sklearn.model_selection import GridSearchCV
from sklearn.neighbors import KNeighborsClassifier

# Step 1: Split features and target
X = df.drop(['Salary', 'High_Salary'], axis=1)
y = df['High_Salary']

# Step 3: Define parameter grid (try k values from 1 to 20)
param_grid = {'n_neighbors': list(range(1, 21))}

# Step 4: Initialize GridSearchCV
grid = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5, scoring='accuracy')

# Step 5: Fit to the scaled data
grid.fit(X_train, y_train)

# Step 6: Print best results
print("Best n_neighbors:", grid.best_params_['n_neighbors'])
print("Best cross-validation accuracy:", grid.best_score_)

from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import cross_val_score

dt_model = DecisionTreeClassifier()
cv_scores = cross_val_score(dt_model, X_train, y_train, cv=5, scoring='accuracy')

print("Cross-validation Accuracy:", cv_scores)
print("Mean Accuracy:", cv_scores.mean())

from sklearn.model_selection import GridSearchCV

param_grid = {
    'max_depth': range(3, 15),
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

grid = GridSearchCV(DecisionTreeClassifier(), param_grid, cv=5, scoring='accuracy')
grid.fit(X_train, y_train)

print("Best Parameters:", grid.best_params_)
print("Best CV Accuracy:", grid.best_score_)

from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, f1_score
from sklearn.model_selection import train_test_split

# Initialize and train a Decision Tree classifier with specified parameters
dt_model_tuned = DecisionTreeClassifier(max_depth=4, min_samples_leaf=1, min_samples_split=2, random_state=42)
dt_model_tuned.fit(X_train, y_train)

# Make predictions on the test set
y_pred_dt_tuned = dt_model_tuned.predict(X_test)

# Calculate accuracy and F1 score
accuracy_dt_tuned = accuracy_score(y_test, y_pred_dt_tuned)
f1_dt_tuned = f1_score(y_test, y_pred_dt_tuned)

print(f"Tuned Decision Tree Accuracy: {accuracy_dt_tuned:.2f}")
print(f"Tuned Decision Tree F1 Score: {f1_dt_tuned:.2f}")

from sklearn.model_selection import cross_val_score
from sklearn.ensemble import RandomForestClassifier

# Assuming X and y are already defined from previous steps

# Initialize Random Forest classifier
rf_model = RandomForestClassifier(random_state=42)

# Perform 5-fold cross-validation
cv_scores = cross_val_score(rf_model, X_train, y_train, cv=5, scoring='accuracy')

print("Cross-validation Accuracy Scores:", cv_scores)
print("Mean Cross-validation Accuracy:", cv_scores.mean())

from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestClassifier

# Define parameter grid for Random Forest
param_grid_rf = {
    'n_estimators': [50, 100, 200],  # Number of trees in the forest
    'max_depth': [None, 10, 20, 30], # Maximum depth of the trees
    'min_samples_split': [2, 5, 10], # Minimum number of samples required to split an internal node
    'min_samples_leaf': [1, 2, 4]    # Minimum number of samples required to be at a leaf node
}

# Initialize GridSearchCV
grid_rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid_rf, cv=5, scoring='accuracy', n_jobs=-1)

# Fit to the data
grid_rf.fit(X_train, y_train)

# Print best results
print("Best Parameters for Random Forest:", grid_rf.best_params_)
print("Best CV Accuracy for Random Forest:", grid_rf.best_score_)

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, f1_score
from sklearn.model_selection import train_test_split

# Assuming X and y are already defined from previous steps
# Assuming the data has been split into X_train, X_test, y_train, y_test

# Initialize and train a Random Forest classifier with specified parameters
rf_model_tuned = RandomForestClassifier(n_estimators=200, max_depth=10, min_samples_split=5, min_samples_leaf=2, random_state=42)
rf_model_tuned.fit(X_train, y_train)

# Make predictions on the test set
y_pred_rf_tuned = rf_model_tuned.predict(X_test)

# Calculate accuracy and F1 score
accuracy_rf_tuned = accuracy_score(y_test, y_pred_rf_tuned)
f1_rf_tuned = f1_score(y_test, y_pred_rf_tuned)

print(f"Tuned Random Forest Accuracy: {accuracy_rf_tuned:.2f}")
print(f"Tuned Random Forest F1 Score: {f1_rf_tuned:.2f}")

from sklearn.svm import SVC
from sklearn.model_selection import cross_val_score

# Initialize SVC model (without feature scaling)
svc_model = SVC(random_state=42)

# Perform 5-fold cross-validation
cv_scores_svc = cross_val_score(svc_model, X_train, y_train, cv=5, scoring='accuracy')

print("Cross-validation Accuracy Scores (SVC without scaling):", cv_scores_svc)
print("Mean Cross-validation Accuracy (SVC without scaling):", cv_scores_svc.mean())

from sklearn.naive_bayes import GaussianNB
from sklearn.model_selection import cross_val_score

# Assuming X and y are already defined from previous steps

# Initialize Gaussian Naive Bayes classifier
gnb_model = GaussianNB()

# Perform 5-fold cross-validation without scaling
cv_scores_gnb = cross_val_score(gnb_model, X_train, y_train, cv=5, scoring='accuracy')

print("Cross-validation Accuracy Scores (Gaussian Naive Bayes without scaling):", cv_scores_gnb)
print("Mean Cross-validation Accuracy (Gaussian Naive Bayes without scaling):", cv_scores_gnb.mean())

from sklearn.ensemble import AdaBoostClassifier
from sklearn.model_selection import cross_val_score

# Assuming X and y are already defined from previous steps

# Initialize AdaBoost classifier
adaboost_model = AdaBoostClassifier(random_state=42)

# Perform 5-fold cross-validation
cv_scores_adaboost = cross_val_score(adaboost_model, X_train, y_train, cv=5, scoring='accuracy')

print("Cross-validation Accuracy Scores (AdaBoost):", cv_scores_adaboost)
print("Mean Cross-validation Accuracy (AdaBoost):", cv_scores_adaboost.mean())

from xgboost import XGBClassifier
from sklearn.model_selection import cross_val_score

# Initialize XGBoost classifier
# You might want to tune hyperparameters later for better performance
xgb_model = XGBClassifier(eval_metric='logloss', random_state=42)

# Perform 5-fold cross-validation
cv_scores_xgb = cross_val_score(xgb_model, X_train, y_train, cv=5, scoring='accuracy')

print("Cross-validation Accuracy Scores (XGBoost):", cv_scores_xgb)
print("Mean Cross-validation Accuracy (XGBoost):", cv_scores_xgb.mean())

from sklearn.ensemble import GradientBoostingClassifier
from sklearn.model_selection import cross_val_score

# Initialize Gradient Boosting classifier
# You might want to tune hyperparameters later
gb_model = GradientBoostingClassifier(random_state=42)

# Perform 5-fold cross-validation on scaled data
cv_scores_gb = cross_val_score(gb_model, X_train, y_train, cv=5, scoring='accuracy')

print("Cross-validation Accuracy Scores (Gradient Boosting):", cv_scores_gb)
print("Mean Cross-validation Accuracy (Gradient Boosting):", cv_scores_gb.mean())

df.info()

"""**VIF**"""

from statsmodels.stats.outliers_influence import variance_inflation_factor
from statsmodels.tools.tools import add_constant
import pandas as pd

# Assuming 'df' is your DataFrame and it contains the features
# Exclude the target variable(s) and any identifier columns
X = df.drop(['Salary', 'High_Salary', 'CollegeCityID'], axis=1)

# Drop one column from each set of one-hot encoded variables to avoid perfect multicollinearity
# and drop the constant term as we are adding it back
# We need to ensure these columns exist before dropping
cols_to_drop_onehot = []
if 'Gender_f' in X.columns:
    cols_to_drop_onehot.append('Gender_f')
if 'Degree_B.Tech/B.E.' in X.columns:
    cols_to_drop_onehot.append('Degree_B.Tech/B.E.')
if 'CollegeState_Uttar Pradesh' in X.columns:
    cols_to_drop_onehot.append('CollegeState_Uttar Pradesh')

specialization_cols = [col for col in X.columns if col.startswith('Specialization_')]
if specialization_cols:
  cols_to_drop_onehot.append(specialization_cols[0])

X = X.drop(cols_to_drop_onehot, axis=1, errors='ignore')

# Calculate VIF for each feature
vif_data = pd.DataFrame()
vif_data["feature"] = X.columns

# Using a loop to calculate VIF for each feature
# This can take some time with many features
vif_data["VIF"] = [variance_inflation_factor(X.values, i)
                          for i in range(X.shape[1])]

# Sort the features by VIF in descending order
vif_data = vif_data.sort_values(by="VIF", ascending=False)

print("Variance Inflation Factor (VIF) for Features:\n")
# Set display option to show full float values
with pd.option_context('display.float_format', '{:.2f}'.format):
    print(vif_data)

# Print VIF status line by line
print("Variance Inflation Factor (VIF) Status:")
for index, row in vif_data.iterrows():
    print(f"{row['feature']}: {row['VIF']:.2f}")

# Remove columns with VIF > 10 (based on previous VIF calculation)
# Let's re-calculate VIF to be sure and then remove
from statsmodels.stats.outliers_influence import variance_inflation_factor
from statsmodels.tools.tools import add_constant
import pandas as pd

# Exclude the target variable(s) and any identifier columns
X = df.drop(['Salary', 'High_Salary', 'CollegeCityID'], axis=1)

# Drop one column from each set of one-hot encoded variables to avoid perfect multicollinearity
# and drop the constant term as we are adding it back
# We need to ensure these columns exist before dropping
cols_to_drop_onehot = []
if 'Gender_f' in X.columns:
    cols_to_drop_onehot.append('Gender_f')
if 'Degree_B.Tech/B.E.' in X.columns:
    cols_to_drop_onehot.append('Degree_B.Tech/B.E.')
if 'CollegeState_Uttar Pradesh' in X.columns:
    cols_to_drop_onehot.append('CollegeState_Uttar Pradesh')

specialization_cols = [col for col in X.columns if col.startswith('Specialization_')]
if specialization_cols:
  cols_to_drop_onehot.append(specialization_cols[0])

X = X.drop(cols_to_drop_onehot, axis=1, errors='ignore')

# Add a constant term to the features for the VIF calculation
X = add_constant(X)

# Calculate VIF for each feature
vif_data = pd.DataFrame()
vif_data["feature"] = X.columns

# Using a loop to calculate VIF for each feature
vif_data["VIF"] = [variance_inflation_factor(X.values, i)
                          for i in range(X.shape[1])]

# Identify columns with VIF > 10 (excluding the constant)
high_vif_cols = vif_data[(vif_data['VIF'] > 10) & (vif_data['feature'] != 'const')]['feature'].tolist()

print("Columns with VIF > 10 to be removed:", high_vif_cols)

# Drop the high VIF columns from the DataFrame
# Make sure to drop them from the original df or create a new one
df_reduced_vif = df.drop(high_vif_cols, axis=1, errors='ignore')

print("\nShape of DataFrame after removing high VIF columns:", df_reduced_vif.shape)

df_reduced_vif

df_reduced_vif.info()

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, f1_score, confusion_matrix

# For demonstration, let's create a binary target variable based on Salary
df_reduced_vif['High_Salary'] = (df_reduced_vif['Salary'] > df_reduced_vif['Salary'].median()).astype(int)

X = df_reduced_vif.drop(['Salary', 'High_Salary'], axis=1)
y = df_reduced_vif['High_Salary']  # Target variable

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)

# Initialize and train a simple classification model
model = LogisticRegression(max_iter=5000) # Increased max_iter for convergence
model.fit(X_train, y_train)
# Make predictions on the test set
y_pred = model.predict(X_test)

# Calculate accuracy and F1 score
accuracy = accuracy_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print(f"Accuracy: {accuracy:.2f}")
print(f"F1 Score: {f1:.2f}")
print("\nConfusion Matrix:")
print(confusion_matrix(y_test, y_pred))

from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, f1_score
from sklearn.model_selection import train_test_split

# Assuming 'df' is already loaded and preprocessed with 'High_Salary' column


# Split data into training and testing sets (using the same split as before for consistency)


# Initialize and train a Decision Tree classifier with specified paramet

# Make predictions on the test se

# Calculate accuracy and F1 score

from sklearn.model_selection import GridSearchCV
from sklearn.neighbors import KNeighborsClassifier


# Step 3: Define parameter grid (try k values from 1 to 20)
param_grid = {'n_neighbors': list(range(1, 21))}

# Step 4: Initialize GridSearchCV
grid = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5, scoring='accuracy')

grid.fit(X_train, y_train)

# Step 6: Print best results
print("Best n_neighbors:", grid.best_params_['n_neighbors'])
print("Best cross-validation accuracy:", grid.best_score_)

from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestClassifier

# Assuming X and y are already defined from previous steps

# Define parameter grid for Random Forest
param_grid_rf = {
    'n_estimators': [50, 100, 200],  # Number of trees in the forest
    'max_depth': [None, 10, 20, 30], # Maximum depth of the trees
    'min_samples_split': [2, 5, 10], # Minimum number of samples required to split an internal node
    'min_samples_leaf': [1, 2, 4]    # Minimum number of samples required to be at a leaf node
}

# Initialize GridSearchCV
grid_rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid_rf, cv=5, scoring='accuracy', n_jobs=-1)

# Fit to the data
grid_rf.fit(X_train, y_train)

# Print best results
print("Best Parameters for Random Forest:", grid_rf.best_params_)
print("Best CV Accuracy for Random Forest:", grid_rf.best_score_)

from sklearn.svm import SVC
from sklearn.model_selection import cross_val_score

# Initialize SVC model (without feature scaling)
svc_model = SVC(random_state=42)

# Perform 5-fold cross-validation
cv_scores_svc = cross_val_score(svc_model, X_train, y_train, cv=5, scoring='accuracy')

print("Cross-validation Accuracy Scores (SVC without scaling):", cv_scores_svc)
print("Mean Cross-validation Accuracy (SVC without scaling):", cv_scores_svc.mean())

from sklearn.naive_bayes import GaussianNB
from sklearn.model_selection import cross_val_score

# Assuming X and y are already defined from previous steps

# Initialize Gaussian Naive Bayes classifier
gnb_model = GaussianNB()

# Perform 5-fold cross-validation without scaling
cv_scores_gnb = cross_val_score(gnb_model, X_train, y_train, cv=5, scoring='accuracy')

print("Cross-validation Accuracy Scores (Gaussian Naive Bayes without scaling):", cv_scores_gnb)
print("Mean Cross-validation Accuracy (Gaussian Naive Bayes without scaling):", cv_scores_gnb.mean())

from sklearn.ensemble import AdaBoostClassifier
from sklearn.model_selection import cross_val_score

# Assuming X and y are already defined from previous steps

# Initialize AdaBoost classifier
adaboost_model = AdaBoostClassifier(random_state=42)

# Perform 5-fold cross-validation
cv_scores_adaboost = cross_val_score(adaboost_model, X_train, y_train, cv=5, scoring='accuracy')

print("Cross-validation Accuracy Scores (AdaBoost):", cv_scores_adaboost)
print("Mean Cross-validation Accuracy (AdaBoost):", cv_scores_adaboost.mean())

from sklearn.ensemble import GradientBoostingClassifier
from sklearn.model_selection import cross_val_score

# Assuming X and y are already defined from previous steps

# Initialize Gradient Boosting classifier
# You might want to tune hyperparameters later
gb_model = GradientBoostingClassifier(random_state=42)

# Perform 5-fold cross-validation on unscaled data
cv_scores_gb = cross_val_score(gb_model, X_train, y_train, cv=5, scoring='accuracy')

print("Cross-validation Accuracy Scores (Gradient Boosting without scaling):", cv_scores_gb)
print("Mean Cross-validation Accuracy (Gradient Boosting without scaling):", cv_scores_gb.mean())

"""# New section

ANN
"""

#(70:30)

import tensorflow as tf

# Split data into training and testing sets using df_reduced_vif
X_train, X_test, y_train, y_test = train_test_split(df_reduced_vif.drop(['Salary', 'High_Salary'], axis=1), df_reduced_vif['High_Salary'], test_size=0.3, random_state=46)

tf.random.set_seed(42)

# STEP1: Creating the model

model= tf.keras.Sequential([
                            tf.keras.layers.Dense(7, activation='relu'),
                            tf.keras.layers.Dense(7, activation='relu'),
                            tf.keras.layers.Dense(5, activation='relu'),
                            tf.keras.layers.Dense(1, activation='sigmoid')
])

# STEP2: Compiling the model

model.compile(loss= tf.keras.losses.binary_crossentropy,
              optimizer= tf.keras.optimizers.Adam(learning_rate=0.001),
              metrics= [tf.keras.metrics.BinaryAccuracy(name='accuracy'),
                        tf.keras.metrics.Precision(name='precision'),
                        tf.keras.metrics.Recall(name='recall')
              ]
              )

# Split data into training and testing sets using df_reduced_vif
X_train, X_test, y_train, y_test = train_test_split(df_reduced_vif.drop(['Salary', 'High_Salary'], axis=1), df_reduced_vif['High_Salary'], test_size=0.3, random_state=46)


# STEP1: Fit the model

history= model.fit(X_train,y_train, epochs= 250)

pd.DataFrame(history.history).plot()

model.summary();

model.evaluate(X_test, y_test)

#(80:20)

X_train, X_test, y_train, y_test = train_test_split(df_reduced_vif.drop(['Salary', 'High_Salary'], axis=1), df_reduced_vif['High_Salary'], test_size=0.2, random_state=46)

tf.random.set_seed(42)

# STEP1: Creating the model

model= tf.keras.Sequential([
                            tf.keras.layers.Dense(10, activation='relu'),
                            tf.keras.layers.Dense(7, activation='relu'),
                            tf.keras.layers.Dense(5, activation='relu'),
                            tf.keras.layers.Dense(1, activation='sigmoid')
])

# STEP2: Compiling the model

model.compile(loss= tf.keras.losses.binary_crossentropy,
              optimizer= tf.keras.optimizers.Adam(learning_rate=0.001),
              metrics= [tf.keras.metrics.BinaryAccuracy(name='accuracy'),
                        tf.keras.metrics.Precision(name='precision'),
                        tf.keras.metrics.Recall(name='recall')
              ]
              )

# STEP1: Fit the model

history= model.fit(X_train, y_train, epochs= 96)

pd.DataFrame(history.history).plot()

model.summary();

model.evaluate(X_test, y_test)

#(60:40)

X_train, X_test, y_train, y_test = train_test_split(df_reduced_vif.drop(['Salary', 'High_Salary'], axis=1), df_reduced_vif['High_Salary'], test_size=0.4, random_state=46)

tf.random.set_seed(42)

# STEP1: Creating the model

model= tf.keras.Sequential([
                            tf.keras.layers.Dense(10, activation='relu'),
                            tf.keras.layers.Dense(7, activation='relu'),
                            tf.keras.layers.Dense(5, activation='relu'),
                            tf.keras.layers.Dense(1, activation='sigmoid')
])

# STEP2: Compiling the model

model.compile(loss= tf.keras.losses.binary_crossentropy,
              optimizer= tf.keras.optimizers.Adam(learning_rate=0.001),
              metrics= [tf.keras.metrics.BinaryAccuracy(name='accuracy'),
                        tf.keras.metrics.Precision(name='precision'),
                        tf.keras.metrics.Recall(name='recall')
              ]
              )

# STEP1: Fit the model

history= model.fit(X_train, y_train, epochs= 125)

pd.DataFrame(history.history).plot()

model.summary();

model.evaluate(X_test, y_test)

#(75:25)

X_train, X_test, y_train, y_test = train_test_split(df_reduced_vif.drop(['Salary', 'High_Salary'], axis=1), df_reduced_vif['High_Salary'], test_size=0.25, random_state=46)

tf.random.set_seed(42)

# STEP1: Creating the model

model= tf.keras.Sequential([
                            tf.keras.layers.Dense(10, activation='relu'),
                            tf.keras.layers.Dense(7, activation='relu'),
                            tf.keras.layers.Dense(5, activation='relu'),
                            tf.keras.layers.Dense(1, activation='sigmoid')
])

# STEP2: Compiling the model

model.compile(loss= tf.keras.losses.binary_crossentropy,
              optimizer= tf.keras.optimizers.Adam(learning_rate=0.001),
              metrics= [tf.keras.metrics.BinaryAccuracy(name='accuracy'),
                        tf.keras.metrics.Precision(name='precision'),
                        tf.keras.metrics.Recall(name='recall')
              ]
              )

# STEP1: Fit the model

history= model.fit(X_train, y_train, epochs= 125)

pd.DataFrame(history.history).plot()

model.summary();

model.evaluate(X_test, y_test)

#different hidden layer architecture

X_train, X_test, y_train, y_test = train_test_split(df_reduced_vif.drop(['Salary', 'High_Salary'], axis=1), df_reduced_vif['High_Salary'], test_size=0.25, random_state=46)

tf.random.set_seed(42)

# STEP1: Creating the model

model= tf.keras.Sequential([
                            tf.keras.layers.Dense(12, activation='relu'),
                            tf.keras.layers.Dense(8, activation='relu'),
                            tf.keras.layers.Dense(4, activation='relu'),
                            tf.keras.layers.Dense(1, activation='sigmoid')
])

# STEP2: Compiling the model

model.compile(loss= tf.keras.losses.binary_crossentropy,
              optimizer= tf.keras.optimizers.Adam(learning_rate=0.001),
              metrics= [tf.keras.metrics.BinaryAccuracy(name='accuracy'),
                        tf.keras.metrics.Precision(name='precision'),
                        tf.keras.metrics.Recall(name='recall')
              ]
              )

# STEP1: Fit the model

history= model.fit(X_train, y_train, epochs= 75)

pd.DataFrame(history.history).plot()

model.summary();

model.evaluate(X_test, y_test)

X_train, X_test, y_train, y_test = train_test_split(df_reduced_vif.drop(['Salary', 'High_Salary'], axis=1), df_reduced_vif['High_Salary'], test_size=0.30, random_state=46)

import tensorflow as tf

model = tf.keras.Sequential([
    tf.keras.layers.Dense(70, activation='relu'),  # Hidden layer 1
    tf.keras.layers.Dense(35, activation='relu'),  # Hidden layer 2
    tf.keras.layers.Dense(20, activation='relu'),  # Hidden layer 3
    tf.keras.layers.Dense(10, activation='relu'),  # Hidden layer 4
    tf.keras.layers.Dense(1, activation='sigmoid') # Output layer
])

model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])
history= model.fit(X_train, y_train, epochs= 125)

model.evaluate(X_test, y_test)

import tensorflow as tf

model = tf.keras.Sequential([
    #tf.keras.layers.Input(shape=(num_features,)),  # Input layer
    tf.keras.layers.Dense(70, activation='relu'),  # Hidden layer 1
    tf.keras.layers.Dense(50, activation='relu'),  # Hidden layer 2
    tf.keras.layers.Dense(35, activation='relu'),  # Hidden layer 3
    tf.keras.layers.Dense(20, activation='relu'),  # Hidden layer 4
    tf.keras.layers.Dense(10, activation='relu'),  # Hidden layer 5
    tf.keras.layers.Dense(1, activation='sigmoid') # Output layer
])

model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])
history= model.fit(X_train, y_train, epochs= 270)

model.evaluate(X_test, y_test)

import tensorflow as tf

# Build the model
model = tf.keras.Sequential([
    #tf.keras.layers.Input(shape=(num_features,)),  # Input layer
    tf.keras.layers.Dense(70, activation='relu'),  # Hidden layer 1
    tf.keras.layers.Dense(60, activation='relu'),  # Hidden layer 2
    tf.keras.layers.Dense(50, activation='relu'),  # Hidden layer 3
    tf.keras.layers.Dense(40, activation='relu'),  # Hidden layer 4
    tf.keras.layers.Dense(30, activation='relu'),  # Hidden layer 5
    tf.keras.layers.Dense(15, activation='relu'),  # Hidden layer 6
    tf.keras.layers.Dense(1, activation='sigmoid') # Output layer
])

# Compile
model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])

# Train the model for 300 epochs
history= model.fit(X_train, y_train, epochs= 270)

model.evaluate(X_test, y_test)

import tensorflow as tf

# Build the model
model = tf.keras.Sequential([
    #tf.keras.layers.Input(shape=(num_features,)),  # Input layer
    tf.keras.layers.Dense(70, activation='relu'),  # Hidden layer 1
    tf.keras.layers.Dense(60, activation='relu'),  # Hidden layer 2
    tf.keras.layers.Dense(50, activation='relu'),  # Hidden layer 3
    tf.keras.layers.Dense(40, activation='relu'),  # Hidden layer 4
    tf.keras.layers.Dense(30, activation='relu'),  # Hidden layer 5
    tf.keras.layers.Dense(20, activation='relu'),  # Hidden layer 6
    tf.keras.layers.Dense(10, activation='relu'),  # Hidden layer 7
    tf.keras.layers.Dense(1, activation='sigmoid') # Output layer
])

# Compile
model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])
history= model.fit(X_train, y_train, epochs= 350)

model.evaluate(X_test, y_test)

df_reduced_vif.shape

import tensorflow as tf

# Build the model
model = tf.keras.Sequential([
    #tf.keras.layers.Input(shape=(num_features,)),  # Input layer
    tf.keras.layers.Dense(70, activation='relu'),  # Hidden layer 1
    tf.keras.layers.Dense(60, activation='tanh'),  # Hidden layer 2
    tf.keras.layers.Dense(50, activation='relu'),  # Hidden layer 3
    tf.keras.layers.Dense(40, activation='tanh'),  # Hidden layer 4
    tf.keras.layers.Dense(30, activation='relu'),  # Hidden layer 5
    tf.keras.layers.Dense(20, activation='tanh'),  # Hidden layer 6
    tf.keras.layers.Dense(10, activation='relu'),  # Hidden layer 7
    tf.keras.layers.Dense(5, activation='tanh'), # Hidden layer 8
    tf.keras.layers.Dense(1, activation='sigmoid') # Output layer
])

# Compile
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
              loss='binary_crossentropy',
              metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])

# Train the model for 300 epochs
history= model.fit(X_train, y_train, epochs= 200)

model.evaluate(X_test, y_test)

